{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Решение практических заданий sklearn. Обучение дерева принятия решений"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Задание\r\n",
                "Скачайте набор данных с тремя переменными: sex, exang, num.  \r\n",
                "Представьте, что при помощи дерева решений мы хотим классифицировать есть или нет у пациента заболевание сердца (переменная num),  \r\n",
                "основываясь на двух признаках: пол (sex) и наличие/отсутсвие стенокардии (exang).  \r\n",
                "Обучите дерево решений на этих данных, используйте entropy в качестве критерия."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import pandas as pd\r\n",
                "\r\n",
                "patient_data = pd.read_csv('https://stepik.org/media/attachments/course/4852/train_data_tree.csv')\r\n",
                "\r\n",
                "X = patient_data[['sex', 'exang']]\r\n",
                "y = patient_data[['num']]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "from sklearn import tree\r\n",
                "\r\n",
                "clf = tree.DecisionTreeClassifier(criterion='entropy')\r\n",
                "clf.fit(X, y)\r\n",
                "\r\n",
                "tree.plot_tree(clf,  filled=True);"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Высчитаем Information Gain для переменной, которая помещена в корень дерева"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "t = clf.tree_\r\n",
                "parent = 0\r\n",
                "child1, child2 = 1, 4\r\n",
                "entropy_parent = t.impurity[parent]\r\n",
                "entropy_children = (t.n_node_samples[child1]/t.n_node_samples[parent] * t.impurity[child1] +\r\n",
                "                  t.n_node_samples[child2]/t.n_node_samples[parent] * t.impurity[child2])\r\n",
                "ig = round(entropy_parent - entropy_children, 3)\r\n",
                "print('IG:', ig)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "IG: 0.119\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Задание\r\n",
                "Опробуем дерево решениц на классическом наборе iris, где собраны данные о длине, ширине чашелистиков и лепестков ирисов и их принадлежности к виду.  \r\n",
                "Итак, вам даны 2 numpy массива с измеренными признаками ирисов и их принадлежностью к виду.  \r\n",
                "Сначала попробуем примитивный способ с разбиением данных на 2 датасэта.  \r\n",
                "Используйте функцию train_test_split для разделения имеющихся данных на тренировочный и тестовый наборы данных, 75% и 25% соответственно.  \r\n",
                "Затем создайте дерево dt с параметрами по умолчанию и обучите его на тренировочных данных,  \r\n",
                "а после предскажите классы, к которым принадлежат данные из тестовой выборки, сохраните результат предсказаний в переменную predicted."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "from sklearn.datasets import load_iris\r\n",
                "from sklearn.model_selection import train_test_split\r\n",
                "\r\n",
                "iris = load_iris()\r\n",
                "X = iris.data\r\n",
                "y = iris.target\r\n",
                "\r\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\r\n",
                "\r\n",
                "dt = tree.DecisionTreeClassifier()\r\n",
                "dt.fit(X_train, y_train)\r\n",
                "\r\n",
                "predicted = dt.predict(X_test)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Задание\r\n",
                "Даны 2 датасэта, к которым вы можете обращаться:  \r\n",
                "* train - размеченный с известными правильным ответами (хранятся в колонке y)\r\n",
                "* test - набор, где нужно предсказать их  \r\n",
                "Найдите дерево с наиболее подходящими параметрами с помощью GridSearchCV и предскажите с его помощью ответов ко 2-ому сэту!  \r\n",
                "\r\n",
                "Границы параметров:\r\n",
                "1. максимальная глубина - от 1 до 10 уровней\r\n",
                "2. минимальное число проб для разделения - от 2 до 10\r\n",
                "3. минимальное число проб в листе - от 1 до 10  \r\n",
                "Названия переменных:лучшее дерево - best_tree, GridSearchCV - search, а предсказания - predictions  "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# import numpy as np\r\n",
                "# import pandas as pd\r\n",
                "# from sklearn.tree import DecisionTreeClassifier\r\n",
                "# from sklearn.model_selection import GridSearchCV\r\n",
                "\r\n",
                "# X = train.drop(['y'], axis=1)\r\n",
                "# y = train.y\r\n",
                "\r\n",
                "# search = GridSearchCV(DecisionTreeClassifier(), param_grid={'max_depth': range(1, 11), 'min_samples_split': range(2, 11), 'min_samples_leaf': range(1, 11)})\r\n",
                "\r\n",
                "# search.fit(X, y)\r\n",
                "\r\n",
                "# best_tree = search.best_estimator_\r\n",
                "\r\n",
                "# predictions = best_tree.predict(test)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Задание\r\n",
                "В sklearn можно её удобно получить с помощью функции confusion_matrix.  \r\n",
                "Вам даны 2 массива с истинными классами наблюдений и предсказанными - y и predictions.  \r\n",
                "Получите по ним confusion matrix и поместите её в переменную conf_matrix."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# import pandas as pd\r\n",
                "# from sklearn.metrics import confusion_matrix\r\n",
                "\r\n",
                "# conf_matrix = confusion_matrix(y, predictions)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Соотнесите описание метрик, которые выводятся из 4-ёх основных параметров, с их названиями.  \r\n",
                "AccuracyAccuracy - Отношение правильно классифицированных наблюдений ко всем  \r\n",
                "$F_{1}-score$ - Отношение удвоенного произведения precision и recall к их сумме  \r\n",
                "Recall, True Positive RateTruePositiveRate, SensitivitySensitivity - Отношение правильно определённых положительных случаев ко всем положительным - показывает какую часть положительных случаев модель правильно классифицирует  \r\n",
                "Specificity, True Negative RateTrueNegativeRate - Отношение правильно определённых отрицательных случаев ко всем отрицательным - показывает какую часть отрицательных случаев модель правильно классифицирует  \r\n",
                "PrecisionPrecision - Отношение правильно определённых положительных наблюдений ко всем определённым как положительные"
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.10 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "188e6a6f1be7acb7ef13240439b1aed38d0658e28f5b11628d8f8d604f4d20f0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}